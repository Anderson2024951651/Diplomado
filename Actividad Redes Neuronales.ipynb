{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UXqJRwEFDHzg",
    "outputId": "19c5253b-6739-41cc-de53-a4e2a1ef290f"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Load MNIST dataset\n",
    "# Definimos una secuencia de transformaciones para aplicar a las imágenes del dataset.\n",
    "# En este caso, solo convertimos las imágenes a tensores utilizando `ToTensor()`.\n",
    "# Esto es necesario para que las imágenes estén en un formato compatible con PyTorch.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # Convierte la imagen de un formato PIL o numpy.ndarray a un tensor.\n",
    "])\n",
    "\n",
    "# Cargamos el dataset MNIST de entrenamiento.\n",
    "# `root='./data'` especifica el directorio donde se descargarán los datos si no están presentes.\n",
    "# `train=True` indica que queremos el conjunto de datos de entrenamiento.\n",
    "# `transform=transform` aplica las transformaciones definidas previamente a cada imagen.\n",
    "# `download=True` descarga los datos si no están disponibles en el directorio especificado.\n",
    "mnist_dataset = datasets.MNIST(\n",
    "    root='./data', train=True, transform=transform, download=True\n",
    ")\n",
    "\n",
    "# Creamos un DataLoader que nos permite cargar los datos en lotes pequeños.\n",
    "# `dataset=mnist_dataset` es el dataset que se cargará.\n",
    "# `batch_size=16` indica que cada lote contendrá 16 imágenes y etiquetas.\n",
    "# `shuffle=True` mezcla los datos aleatoriamente en cada época, mejorando la generalización del modelo.\n",
    "data_loader = DataLoader(\n",
    "    mnist_dataset, batch_size=16, shuffle=True\n",
    ")\n",
    "\n",
    "# Obtenemos un único lote de datos del DataLoader.\n",
    "# `next(iter(data_loader))` convierte el DataLoader en un iterador y toma el primer lote.\n",
    "# El lote contiene `images` (los tensores de las imágenes) y `labels` (las etiquetas correspondientes).\n",
    "images, labels = next(iter(data_loader))\n",
    "\n",
    "\n",
    "# Plot the images in a grid\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(images[i].squeeze(), cmap='gray')\n",
    "    plt.title(f'Label: {labels[i].item()}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UT7LMM57CqC6",
    "outputId": "698dda5e-9c78-4a2a-b65b-8a22aec7eedc"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Definimos el modelo MLP\n",
    "# MLP hereda de nn.Module, lo que permite utilizar las funciones y propiedades de PyTorch\n",
    "# para crear, entrenar y evaluar redes neuronales.\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Inicializamos la clase base nn.Module\n",
    "        # Esto habilita funciones esenciales como la gestión de capas y forward pass.\n",
    "        super(MLP, self).__init__()\n",
    "        # Capa completamente conectada: de entrada (28x28 píxeles) a 512 neuronas\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)\n",
    "        # Capa oculta: de 512 neuronas a 256 neuronas\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        # Capa de salida: de 256 neuronas a 10 clases (números del 0 al 9)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        \n",
    "        #self.fc4 = nn.Linear(10, 10)\n",
    "        # Función de activación ReLU\n",
    "        self.relu = nn.ReLU()\n",
    "        # Dropout para evitar sobreajuste\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    # Definimos cómo pasa la información a través de la red\n",
    "    # Este método es obligatorio en las clases que heredan de nn.Module.\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Aplanamos las imágenes (de 28x28 a 1D)\n",
    "        x = self.relu(self.fc1(x))  # Aplicamos la primera capa y ReLU\n",
    "        x = self.dropout(x)         # Aplicamos Dropout\n",
    "        x = self.relu(self.fc2(x))  # Aplicamos la segunda capa y ReLU\n",
    "        x = self.dropout(x)         # Aplicamos Dropout\n",
    "        x = self.fc3(x)             # Aplicamos la capa de salida\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época [1/10], Pérdida: 0.1670\n",
      "Época [2/10], Pérdida: 0.1589\n",
      "Época [3/10], Pérdida: 0.2436\n",
      "Época [4/10], Pérdida: 0.0605\n",
      "Época [5/10], Pérdida: 0.3473\n",
      "Época [6/10], Pérdida: 0.2582\n",
      "Época [7/10], Pérdida: 0.0085\n",
      "Época [8/10], Pérdida: 0.0305\n",
      "Época [9/10], Pérdida: 0.0804\n",
      "Época [10/10], Pérdida: 0.0606\n"
     ]
    }
   ],
   "source": [
    "# Hiperparámetros\n",
    "batch_size = 64       # Tamaño de lote\n",
    "learning_rate = 0.001 # Tasa de aprendizaje\n",
    "epochs = 10           # Número de épocas de entrenamiento\n",
    "\n",
    "# Preprocesamiento y carga de datos de MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                 # Convertimos imágenes a tensores\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalizamos a media 0 y varianza 1\n",
    "])\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data', train=True, transform=transform, download=True)  # Dataset de entrenamiento\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data', train=False, transform=transform, download=True)  # Dataset de prueba\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset, batch_size=batch_size, shuffle=True)  # Dataloader para entrenamiento\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, batch_size=batch_size, shuffle=False)  # Dataloader para prueba\n",
    "\n",
    "# Definimos el modelo, la función de pérdida y el optimizador\n",
    "model = MLP()                             # Creamos una instancia del modelo MLP\n",
    "criterion = nn.CrossEntropyLoss()         # Función de pérdida para clasificación\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Optimizador Adam\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Ponemos el modelo en modo entrenamiento\n",
    "    for images, labels in train_loader:  # Iteramos sobre lotes de datos\n",
    "        optimizer.zero_grad()            # Reiniciamos los gradientes\n",
    "        outputs = model(images)          # Hacemos una predicción con el modelo\n",
    "        loss = criterion(outputs, labels)  # Calculamos la pérdida\n",
    "        loss.backward()                  # Propagamos los gradientes\n",
    "        optimizer.step()                 # Actualizamos los pesos del modelo\n",
    "\n",
    "    # Mostramos la pérdida al final de cada época\n",
    "    print(f\"Época [{epoch+1}/{epochs}], Pérdida: {loss.item():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tTyHa34XCrxN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en el conjunto de prueba: 97.76%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Ponemos el modelo en modo evaluación (desactiva Dropout)\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # Desactivamos el cálculo de gradientes para evaluación\n",
    "    for images, labels in test_loader:  # Iteramos sobre los datos de prueba\n",
    "        outputs = model(images)         # Hacemos predicciones\n",
    "        _, predicted = torch.max(outputs.data, 1)  # Obtenemos la clase con mayor probabilidad\n",
    "        total += labels.size(0)         # Total de muestras evaluadas\n",
    "        correct += (predicted == labels).sum().item()  # Contamos las predicciones correctas\n",
    "\n",
    "# Calculamos y mostramos la precisión del modelo\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy en el conjunto de prueba: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________\n",
    "-PREGUNTA 2.1.1\n",
    "\n",
    "(PERCEPTRON MULTICAPA) MODIFICACIONES EN LA ARQUITECTURA\n",
    "\n",
    "    El profesor indicó variar solo un parámetro de los indicados en el enunciado.\n",
    "\n",
    "RESPUESTA:\n",
    "\n",
    "    Elegí modificar el número de neuronas por capa. En primera instancia, ejecuté la simulación con la configuración original:\n",
    "        -Configuración inicial:\n",
    "        28x28 a 512 \n",
    "        512 a 256\n",
    "        256 a 10\n",
    "    Luego, ejecuté la simulación reduciendo el número de neuronas por capa:\n",
    "        -Configuración modificada:\n",
    "        28x28 a 256\n",
    "        256 a 128\n",
    "        128 a 10\n",
    "    Respecto a la configuración inicial, se obtuvo un Accuracy de 97.71% y una Pérdida final de 0.3409. Mientras que, con la reducción de neuronas obtuvimos un Accuracy de 97.63% y una Pérdida final de 0.2091. Esto puede indicar que mediante la configuración inicial se tenía un sobreajuste el cual fue mejorado mediante la reducción de neuronas. \n",
    "\n",
    "Aqui copio los resultados de la simulación:\n",
    "\n",
    "-Configuración inicial:\n",
    "Accuracy en el conjunto de prueba: 97.71%\n",
    "\n",
    "Época [1/10], Pérdida: 0.2059\n",
    "\n",
    "Época [2/10], Pérdida: 0.0869\n",
    "\n",
    "Época [3/10], Pérdida: 0.2697\n",
    "\n",
    "Época [4/10], Pérdida: 0.0565\n",
    "\n",
    "Época [5/10], Pérdida: 0.0207\n",
    "\n",
    "Época [6/10], Pérdida: 0.0152\n",
    "\n",
    "Época [7/10], Pérdida: 0.0440\n",
    "\n",
    "Época [8/10], Pérdida: 0.0307\n",
    "\n",
    "Época [9/10], Pérdida: 0.0755\n",
    "\n",
    "Época [10/10], Pérdida: 0.3409\n",
    "\n",
    "-Configuración mejorada:\n",
    "Accuracy en el conjunto de prueba: 97.63%\n",
    "\n",
    "Época [1/10], Pérdida: 0.1905\n",
    "\n",
    "Época [2/10], Pérdida: 0.2809\n",
    "\n",
    "Época [3/10], Pérdida: 0.0601\n",
    "\n",
    "Época [4/10], Pérdida: 0.6275\n",
    "\n",
    "Época [5/10], Pérdida: 0.0271\n",
    "\n",
    "Época [6/10], Pérdida: 0.0351\n",
    "\n",
    "Época [7/10], Pérdida: 0.0469\n",
    "\n",
    "Época [8/10], Pérdida: 0.0619\n",
    "\n",
    "Época [9/10], Pérdida: 0.0178\n",
    "\n",
    "Época [10/10], Pérdida: 0.2091\n",
    "\n",
    "\n",
    "______________________________________\n",
    "-PREGUNTA 2.1.2\n",
    "\n",
    "(PERCEPTRON MULTICAPA) MODIFICACIONES EN EL ENTRENAMIENTO:\n",
    "\n",
    "    El profesor indicó variar solo un parámetro de los indicados en el enunciado.\n",
    "\n",
    "RESPUESTA:\n",
    "\n",
    "En esta pregunta opté por variar la Tasa de Aprendizaje. Al respecto, se probaron los valores de 0.01, 0.001 y 0.0001. Los resultados se muestran mas abajo. Ahora bien, es mas recomendable una Tasa de Aprendizaje de 0.001, debido a que se obtiene la precisión mas alta entre los valores sometidos a prueba. Asimismo, para esta Tasa de Aprendizaje observamos que la Pérdida disminuye de manera constante entre las épocas. Notemos que una Tasa de 0.01, provoca un comportamiento errático de la Pérdida, y la precisión case a 90.67%. Mientras que, la Tasa de 0.0001 es mas lenta de converger sin obtener una precisión mas elevada que cuando simulamos con la Tasa de 0.001. En ese sentido, es recomendable la Tasa de Aprendizaje de 0.001.\n",
    "\n",
    "\n",
    "Para un learning_rate = 0.01 # Tasa de aprendizaje\n",
    "\n",
    "90.67% de Accuracy\n",
    "\n",
    "Época [1/10], Pérdida: 0.6149\n",
    "\n",
    "Época [2/10], Pérdida: 0.6427\n",
    "\n",
    "Época [3/10], Pérdida: 0.3958\n",
    "\n",
    "Época [4/10], Pérdida: 0.7424\n",
    "\n",
    "Época [5/10], Pérdida: 0.4870\n",
    "\n",
    "Época [6/10], Pérdida: 0.3082\n",
    "\n",
    "Época [7/10], Pérdida: 0.6939\n",
    "\n",
    "Época [8/10], Pérdida: 0.4401\n",
    "\n",
    "Época [9/10], Pérdida: 1.2409\n",
    "\n",
    "Época [10/10], Pérdida: 0.2865\n",
    "\n",
    "\n",
    "Para un learning_rate = 0.001 # Tasa de aprendizaje\n",
    "\n",
    "97.63% de Accuracy\n",
    "\n",
    "Época [1/10], Pérdida: 0.1905\n",
    "\n",
    "Época [2/10], Pérdida: 0.2809\n",
    "\n",
    "Época [3/10], Pérdida: 0.0601\n",
    "\n",
    "Época [4/10], Pérdida: 0.6275\n",
    "\n",
    "Época [5/10], Pérdida: 0.0271\n",
    "\n",
    "Época [6/10], Pérdida: 0.0351\n",
    "\n",
    "Época [7/10], Pérdida: 0.0469\n",
    "\n",
    "Época [8/10], Pérdida: 0.0619\n",
    "\n",
    "Época [9/10], Pérdida: 0.0178\n",
    "\n",
    "Época [10/10], Pérdida: 0.2091\n",
    "\n",
    "\n",
    "Para un learning_rate = 0.0001 # Tasa de aprendizaje\n",
    "\n",
    "97.07% de Accuracy\n",
    "\n",
    "Época [1/10], Pérdida: 0.4513\n",
    "\n",
    "Época [2/10], Pérdida: 0.3692\n",
    "\n",
    "Época [3/10], Pérdida: 0.0708\n",
    "\n",
    "Época [4/10], Pérdida: 0.4734\n",
    "\n",
    "Época [5/10], Pérdida: 0.3835\n",
    "\n",
    "Época [6/10], Pérdida: 0.0805\n",
    "\n",
    "Época [7/10], Pérdida: 0.0880\n",
    "\n",
    "Época [8/10], Pérdida: 0.1680\n",
    "\n",
    "Época [9/10], Pérdida: 0.0224\n",
    "\n",
    "Época [10/10], Pérdida: 0.0565\n",
    "_____________________________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar si hay una GPU disponible, de lo contrario usar la CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Preprocesamiento: Definir transformaciones para los datos\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                # Convertir imágenes a tensores\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalizar los valores a un rango de [-1, 1]\n",
    "])\n",
    "\n",
    "# Cargar el conjunto de datos MNIST\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)  # Datos de entrenamiento\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)  # Datos de prueba\n",
    "\n",
    "# Crear DataLoaders para manejar los datos de forma eficiente\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)   # Loader para entrenamiento (batch de 128, mezclado)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)    # Loader para prueba (batch de 128, sin mezclar)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, verbose=False, filters_l1=32, filters_l2=64, dropout=0.2, final_layer_size=128):\n",
    "        super(CNN, self).__init__()\n",
    "        self.verbose = verbose\n",
    "        self.filters_l1 = filters_l1\n",
    "        self.filters_l2 = filters_l2\n",
    "        self.dropout_rate = dropout\n",
    "        self.final_layer_size = final_layer_size\n",
    "\n",
    "        # Primera capa convolucional\n",
    "        self.conv1 = nn.Conv2d(1, self.filters_l1, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Segunda capa convolucional\n",
    "        self.conv2 = nn.Conv2d(self.filters_l1, self.filters_l2, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Calcular automáticamente las dimensiones de la capa lineal (fc1)\n",
    "        self.fc1_input_size = self._calculate_fc1_input_size()\n",
    "        \n",
    "        # Primera capa completamente conectada\n",
    "        self.fc1 = nn.Linear(self.fc1_input_size, self.final_layer_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "        self.fc2 = nn.Linear(self.final_layer_size, 10)  # Capa de salida para 10 clases (MNIST)\n",
    "\n",
    "    def _calculate_fc1_input_size(self):\n",
    "        \"\"\"\n",
    "        Calcula automáticamente el tamaño de la entrada para la primera capa completamente conectada (fc1).\n",
    "        Simula una pasada con una imagen de prueba de tamaño (1, 28, 28).\n",
    "        \"\"\"\n",
    "        with torch.no_grad():  # Desactiva gradientes\n",
    "            x = torch.randn(1, 1, 28, 28)  # Tensor ficticio de entrada con tamaño MNIST (batch_size=1)\n",
    "            x = self.pool(torch.relu(self.conv1(x)))  # Aplicar Conv1 -> Pool\n",
    "            x = self.pool(torch.relu(self.conv2(x)))  # Aplicar Conv2 -> Pool\n",
    "            fc1_input_size = x.numel()  # Calcular número total de elementos\n",
    "        return fc1_input_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.verbose: \n",
    "            print(f\"Entrada: {x.shape}\")  # Imprime la dimensión de la entrada\n",
    "\n",
    "        # Primera capa convolucional, ReLU y MaxPooling\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        if self.verbose:\n",
    "            print(f\"Después de Conv1 y MaxPooling: {x.shape}\")  # Dimensión después de Conv1 y Pool\n",
    "\n",
    "        # Segunda capa convolucional, ReLU y MaxPooling\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        if self.verbose:\n",
    "            print(f\"Después de Conv2 y MaxPooling: {x.shape}\")  # Dimensión después de Conv2 y Pool\n",
    "\n",
    "        # Aplanar las características 2D a 1D\n",
    "        x = x.view(-1, self.fc1_input_size)\n",
    "        if self.verbose:\n",
    "            print(f\"Después de Aplanamiento: {x.shape}\")  # Dimensión después de Flatten\n",
    "\n",
    "        # Primera capa completamente conectada\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        if self.verbose:\n",
    "            print(f\"Después de Fully Connected (fc1): {x.shape}\")  # Dimensión después de fc1\n",
    "\n",
    "        # Aplicar Dropout\n",
    "        x = self.dropout(x)\n",
    "        if self.verbose:\n",
    "            print(f\"Después de Dropout: {x.shape}\")  # Dimensión después de Dropout\n",
    "\n",
    "        # Capa de salida\n",
    "        x = self.fc2(x)\n",
    "        if self.verbose:\n",
    "            print(f\"Después de Fully Connected (fc2): {x.shape}\")  # Dimensión después de fc2 (salida final)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.4444, Test Accuracy: 0.9734\n",
      "Epoch [2/10], Loss: 0.1400, Test Accuracy: 0.9826\n",
      "Epoch [3/10], Loss: 0.1055, Test Accuracy: 0.9850\n",
      "Epoch [4/10], Loss: 0.0867, Test Accuracy: 0.9860\n",
      "Epoch [5/10], Loss: 0.0715, Test Accuracy: 0.9874\n",
      "Epoch [6/10], Loss: 0.0681, Test Accuracy: 0.9879\n",
      "Epoch [7/10], Loss: 0.0597, Test Accuracy: 0.9891\n",
      "Epoch [8/10], Loss: 0.0549, Test Accuracy: 0.9878\n",
      "Epoch [9/10], Loss: 0.0493, Test Accuracy: 0.9895\n",
      "Epoch [10/10], Loss: 0.0455, Test Accuracy: 0.9892\n",
      "Final Test Accuracy: 0.9892\n"
     ]
    }
   ],
   "source": [
    "# Inicializar el modelo, la función de pérdida y el optimizador\n",
    "model = CNN(verbose=False, filters_l1=8, filters_l2=32, dropout=0.5, final_layer_size=128).to(device)                             # Mover el modelo a la GPU/CPU\n",
    "criterion = nn.CrossEntropyLoss()                    # Función de pérdida para clasificación multiclase\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # Optimizador Adam con tasa de aprendizaje 0.001\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)  # Usando SGD con momento\n",
    "#optimizer = optim.RMSprop(model.parameters(), lr=0.001)  # Usando RMSprop\n",
    "#optimizer = optim.Adagrad(model.parameters(), lr=0.01)  # Usando Adagrad\n",
    "#optimizer = optim.Adadelta(model.parameters(), lr=1.0)  # Usando Adadelta\n",
    "\n",
    "\n",
    "\n",
    "# Definir la función de entrenamiento\n",
    "def train(model, loader, criterion, optimizer, device):\n",
    "    model.train()  # Establecer el modelo en modo de entrenamiento\n",
    "    running_loss = 0.0\n",
    "    for images, labels in loader:  # Iterar sobre los lotes de datos\n",
    "        images, labels = images.to(device), labels.to(device)  # Mover los datos a la GPU/CPU\n",
    "\n",
    "        optimizer.zero_grad()       # Reiniciar los gradientes\n",
    "        outputs = model(images)     # Paso hacia adelante\n",
    "        loss = criterion(outputs, labels)  # Calcular la pérdida\n",
    "        loss.backward()             # Paso hacia atrás (cálculo de gradientes)\n",
    "        optimizer.step()            # Actualizar los pesos\n",
    "\n",
    "        running_loss += loss.item()  # Acumular la pérdida\n",
    "    return running_loss / len(loader)  # Devolver la pérdida promedio\n",
    "\n",
    "# Definir la función de evaluación\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()  # Establecer el modelo en modo de evaluación\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # Deshabilitar el cálculo de gradientes para ahorrar memoria\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Mover datos a la GPU/CPU\n",
    "            outputs = model(images)  # Paso hacia adelante\n",
    "            _, predicted = torch.max(outputs, 1)  # Obtener las predicciones (clase con mayor probabilidad)\n",
    "            total += labels.size(0)  # Contar el número total de ejemplos\n",
    "            correct += (predicted == labels).sum().item()  # Contar las predicciones correctas\n",
    "    return correct / total  # Calcular la precisión\n",
    "\n",
    "# Bucle principal de entrenamiento\n",
    "num_epochs = 10  # Número de épocas\n",
    "for epoch in range(num_epochs):\n",
    "    # Entrenar el modelo y calcular la pérdida\n",
    "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "    # Evaluar el modelo en el conjunto de prueba\n",
    "    test_accuracy = evaluate(model, test_loader, device)\n",
    "    # Imprimir los resultados de la época actual\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Calcular la precisión final en el conjunto de prueba\n",
    "final_accuracy = evaluate(model, test_loader, device)\n",
    "print(f\"Final Test Accuracy: {final_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________\n",
    "PREGUNTA 2.2.1\n",
    "\n",
    "(REDES CONVOLUCIONALES) MODIFICACIONES DE LA ARQUITECTURA:\n",
    "\n",
    "    El profesor indicó variar solo un parámetro de los indicados en el enunciado.\n",
    "\n",
    "RESPUESTA: \n",
    "\n",
    "Decidí probar los valores de 0.2, 0.3, 0.4 y 0.5 para el Dropout de la red neuronal convolucional. Los resultados se presentan mas adelante. Ahora bien, el Dropout mas recomendable es 0.5, debido a que con este valor obtengo el máximo Accuracy (99.20%) es decir una mejor precisión final. Asimismo, con un Dropout de 0.5 se muestra una reducción constante de las Pérdidas, esto significa que el modelo esta evitó el sobreajuste sin afectar el rendimiento.\n",
    "\n",
    "RESULTADOS: \n",
    "-Dropout=0.2\n",
    "\n",
    "Epoch [1/10], Loss: 0.3858, Test Accuracy: 0.9698\n",
    "\n",
    "Epoch [2/10], Loss: 0.0990, Test Accuracy: 0.9824\n",
    "\n",
    "Epoch [3/10], Loss: 0.0717, Test Accuracy: 0.9837\n",
    "\n",
    "Epoch [4/10], Loss: 0.0577, Test Accuracy: 0.9860\n",
    "\n",
    "Epoch [5/10], Loss: 0.0500, Test Accuracy: 0.9887\n",
    "\n",
    "Epoch [6/10], Loss: 0.0403, Test Accuracy: 0.9890\n",
    "\n",
    "Epoch [7/10], Loss: 0.0361, Test Accuracy: 0.9907\n",
    "\n",
    "Epoch [8/10], Loss: 0.0324, Test Accuracy: 0.9888\n",
    "\n",
    "Epoch [9/10], Loss: 0.0295, Test Accuracy: 0.9900\n",
    "\n",
    "Epoch [10/10], Loss: 0.0262, Test Accuracy: 0.9913\n",
    "\n",
    "Final Test Accuracy: 0.9913\n",
    "\n",
    "\n",
    "-Dropout=0.3\n",
    "\n",
    "Epoch [1/10], Loss: 0.3936, Test Accuracy: 0.9745\n",
    "\n",
    "Epoch [2/10], Loss: 0.1070, Test Accuracy: 0.9811\n",
    "\n",
    "Epoch [3/10], Loss: 0.0750, Test Accuracy: 0.9856\n",
    "\n",
    "Epoch [4/10], Loss: 0.0627, Test Accuracy: 0.9862\n",
    "\n",
    "Epoch [5/10], Loss: 0.0519, Test Accuracy: 0.9878\n",
    "\n",
    "Epoch [6/10], Loss: 0.0452, Test Accuracy: 0.9904\n",
    "\n",
    "Epoch [7/10], Loss: 0.0397, Test Accuracy: 0.9897\n",
    "\n",
    "Epoch [8/10], Loss: 0.0359, Test Accuracy: 0.9899\n",
    "\n",
    "Epoch [9/10], Loss: 0.0333, Test Accuracy: 0.9907\n",
    "\n",
    "Epoch [10/10], Loss: 0.0286, Test Accuracy: 0.9903\n",
    "\n",
    "Final Test Accuracy: 0.9903\n",
    "\n",
    "\n",
    "-Dropout=0.4\n",
    "\n",
    "Epoch [1/10], Loss: 0.3417, Test Accuracy: 0.9781\n",
    "\n",
    "Epoch [2/10], Loss: 0.0955, Test Accuracy: 0.9852\n",
    "\n",
    "Epoch [3/10], Loss: 0.0701, Test Accuracy: 0.9881\n",
    "\n",
    "Epoch [4/10], Loss: 0.0603, Test Accuracy: 0.9879\n",
    "\n",
    "Epoch [5/10], Loss: 0.0510, Test Accuracy: 0.9860\n",
    "\n",
    "Epoch [6/10], Loss: 0.0456, Test Accuracy: 0.9906\n",
    "\n",
    "Epoch [7/10], Loss: 0.0403, Test Accuracy: 0.9904\n",
    "\n",
    "Epoch [8/10], Loss: 0.0359, Test Accuracy: 0.9900\n",
    "\n",
    "Epoch [9/10], Loss: 0.0345, Test Accuracy: 0.9901\n",
    "\n",
    "Epoch [10/10], Loss: 0.0308, Test Accuracy: 0.9906\n",
    "\n",
    "Final Test Accuracy: 0.9906\n",
    "\n",
    "\n",
    "-Dropout=0.5\n",
    "\n",
    "Epoch [1/10], Loss: 0.3837, Test Accuracy: 0.9764\n",
    "\n",
    "Epoch [2/10], Loss: 0.1193, Test Accuracy: 0.9834\n",
    "\n",
    "Epoch [3/10], Loss: 0.0871, Test Accuracy: 0.9872\n",
    "\n",
    "Epoch [4/10], Loss: 0.0701, Test Accuracy: 0.9885\n",
    "\n",
    "Epoch [5/10], Loss: 0.0603, Test Accuracy: 0.9903\n",
    "\n",
    "Epoch [6/10], Loss: 0.0532, Test Accuracy: 0.9911\n",
    "\n",
    "Epoch [7/10], Loss: 0.0443, Test Accuracy: 0.9909\n",
    "\n",
    "Epoch [8/10], Loss: 0.0424, Test Accuracy: 0.9913\n",
    "\n",
    "Epoch [9/10], Loss: 0.0387, Test Accuracy: 0.9915\n",
    "\n",
    "Epoch [10/10], Loss: 0.0359, Test Accuracy: 0.9920\n",
    "\n",
    "Final Test Accuracy: 0.9920\n",
    "______________\n",
    "PREGUNTA 2.2.2\n",
    "\n",
    "(REDES CONVOLUCIONALES) MODIFICACIONES DEL ENTRENAMIENTO:\n",
    "\n",
    "    El profesor indicó variar solo un parámetro de los indicados en el enunciado.\n",
    "\n",
    "RESPUESTA: \n",
    "\n",
    "Considero que Adam es el optimizador más recomendable para este caso, debido a que obtuve la mayor presición Accuracy de 0.9915. Asimismo, la ventaja de este optimizador es que no requiere sintonización de parámetros adicionales como SGD donde ajustamos el momentum=0.9.\n",
    "\n",
    "RESULTADOS:\n",
    "\n",
    "1.Optimizador: optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "Epoch [1/10], Loss: 0.4064, Test Accuracy: 0.9749\n",
    "\n",
    "Epoch [2/10], Loss: 0.1224, Test Accuracy: 0.9840\n",
    "\n",
    "Epoch [3/10], Loss: 0.0916, Test Accuracy: 0.9860\n",
    "\n",
    "Epoch [4/10], Loss: 0.0753, Test Accuracy: 0.9891\n",
    "\n",
    "Epoch [5/10], Loss: 0.0674, Test Accuracy: 0.9876\n",
    "\n",
    "Epoch [6/10], Loss: 0.0615, Test Accuracy: 0.9904\n",
    "\n",
    "Epoch [7/10], Loss: 0.0529, Test Accuracy: 0.9899\n",
    "\n",
    "Epoch [8/10], Loss: 0.0495, Test Accuracy: 0.9893\n",
    "\n",
    "Epoch [9/10], Loss: 0.0446, Test Accuracy: 0.9910\n",
    "\n",
    "Epoch [10/10], Loss: 0.0438, Test Accuracy: 0.9915\n",
    "\n",
    "Final Test Accuracy: 0.9915\n",
    "\n",
    "2.Optimizador: optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "Epoch [1/10], Loss: 0.5697, Test Accuracy: 0.9741\n",
    "\n",
    "Epoch [2/10], Loss: 0.1302, Test Accuracy: 0.9817\n",
    "\n",
    "Epoch [3/10], Loss: 0.0973, Test Accuracy: 0.9835\n",
    "\n",
    "Epoch [4/10], Loss: 0.0808, Test Accuracy: 0.9864\n",
    "\n",
    "Epoch [5/10], Loss: 0.0707, Test Accuracy: 0.9873\n",
    "\n",
    "Epoch [6/10], Loss: 0.0629, Test Accuracy: 0.9878\n",
    "\n",
    "Epoch [7/10], Loss: 0.0554, Test Accuracy: 0.9889\n",
    "\n",
    "Epoch [8/10], Loss: 0.0510, Test Accuracy: 0.9888\n",
    "\n",
    "Epoch [9/10], Loss: 0.0469, Test Accuracy: 0.9906\n",
    "\n",
    "Epoch [10/10], Loss: 0.0426, Test Accuracy: 0.9896\n",
    "\n",
    "Final Test Accuracy: 0.9896\n",
    "\n",
    "3.Optimizador: optim.RMSprop(model.parameters(), lr=0.001)\n",
    "\n",
    "Epoch [1/10], Loss: 0.3068, Test Accuracy: 0.9773\n",
    "\n",
    "Epoch [2/10], Loss: 0.1178, Test Accuracy: 0.9814\n",
    "\n",
    "Epoch [3/10], Loss: 0.0901, Test Accuracy: 0.9853\n",
    "\n",
    "Epoch [4/10], Loss: 0.0763, Test Accuracy: 0.9876\n",
    "\n",
    "Epoch [5/10], Loss: 0.0653, Test Accuracy: 0.9888\n",
    "\n",
    "Epoch [6/10], Loss: 0.0593, Test Accuracy: 0.9894\n",
    "\n",
    "Epoch [7/10], Loss: 0.0524, Test Accuracy: 0.9895\n",
    "\n",
    "Epoch [8/10], Loss: 0.0467, Test Accuracy: 0.9888\n",
    "\n",
    "Epoch [9/10], Loss: 0.0433, Test Accuracy: 0.9887\n",
    "\n",
    "Epoch [10/10], Loss: 0.0390, Test Accuracy: 0.9888\n",
    "\n",
    "Final Test Accuracy: 0.9888\n",
    "\n",
    "4.Optimizador: optim.Adagrad(model.parameters(), lr=0.01)\n",
    "\n",
    "Epoch [1/10], Loss: 0.2980, Test Accuracy: 0.9741\n",
    "\n",
    "Epoch [2/10], Loss: 0.1250, Test Accuracy: 0.9810\n",
    "\n",
    "Epoch [3/10], Loss: 0.0999, Test Accuracy: 0.9848\n",
    "\n",
    "Epoch [4/10], Loss: 0.0874, Test Accuracy: 0.9852\n",
    "\n",
    "Epoch [5/10], Loss: 0.0796, Test Accuracy: 0.9866\n",
    "\n",
    "Epoch [6/10], Loss: 0.0742, Test Accuracy: 0.9865\n",
    "\n",
    "Epoch [7/10], Loss: 0.0687, Test Accuracy: 0.9881\n",
    "\n",
    "Epoch [8/10], Loss: 0.0661, Test Accuracy: 0.9878\n",
    "\n",
    "Epoch [9/10], Loss: 0.0602, Test Accuracy: 0.9876\n",
    "\n",
    "Epoch [10/10], Loss: 0.0585, Test Accuracy: 0.9889\n",
    "\n",
    "Final Test Accuracy: 0.9889\n",
    "\n",
    "5.Optimizador: optim.Adadelta(model.parameters(), lr=1.0)\n",
    "\n",
    "Epoch [1/10], Loss: 0.2796, Test Accuracy: 0.9799\n",
    "\n",
    "Epoch [2/10], Loss: 0.0810, Test Accuracy: 0.9843\n",
    "\n",
    "Epoch [3/10], Loss: 0.0654, Test Accuracy: 0.9886\n",
    "\n",
    "Epoch [4/10], Loss: 0.0534, Test Accuracy: 0.9875\n",
    "\n",
    "Epoch [5/10], Loss: 0.0465, Test Accuracy: 0.9903\n",
    "\n",
    "Epoch [6/10], Loss: 0.0410, Test Accuracy: 0.9909\n",
    "\n",
    "Epoch [7/10], Loss: 0.0391, Test Accuracy: 0.9902\n",
    "\n",
    "Epoch [8/10], Loss: 0.0359, Test Accuracy: 0.9903\n",
    "\n",
    "Epoch [9/10], Loss: 0.0324, Test Accuracy: 0.9913\n",
    "\n",
    "Epoch [10/10], Loss: 0.0315, Test Accuracy: 0.9900\n",
    "\n",
    "Final Test Accuracy: 0.9900\n",
    "\n",
    "_____________________\n",
    "2.3 COMPARACIÓN\n",
    "\n",
    "En los experimentos que realicé, comparé dos enfoques principales: el Perceptrón Multicapa (MLP) y las Redes Neuronales Convolucionales (CNN), cada uno con diferentes ajustes en su arquitectura y parámetros de entrenamiento. Al trabajar con el MLP, noté que el Accuracy variaba ligeramente al reducir el número de neuronas por capa, aunque el modelo seguía obteniendo resultados bastante buenos. La reducción de neuronas mejoró la Pérdida, lo que me hizo intuir que la configuración original podía haber tenido cierto sobreajuste. Por otro lado, las CNN demostraron una mayor precisión Accuracy, alcanzando una precisión de hasta el 99.20% con un valor de Dropout=0.5, lo que me indicó que el modelo pudo evitar el sobreajuste sin perder precisión Accuracy. En general, las redes convolucionales superaron al MLP en cuanto a precisión, lo que me lleva a la conclusión de que son más adecuadas para tareas de clasificación de imágenes, gracias a su capacidad para extraer características de manera jerárquica y regularizar efectivamente mediante Dropout. Además, las CNN tienen menos parámetros que el MLP debido a la estructura de sus capas, lo que las hace más eficientes para este tipo de tareas. Adicionalmente, con el ajuste final, el MLP se ejecutó en 3min con 50segundos, mientras que, la red neuronal convolucional se ejecutó en 6minutos con 25segundos. Finalemnte, aunque la CNN requiere más tiempo de ejecución, se obtuvo una mejor generalización y se evitó el sobreajuste, lo que resultó en una precisión Accuracy superior al del MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
